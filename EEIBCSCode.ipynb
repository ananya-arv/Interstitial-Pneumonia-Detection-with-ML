{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFEedJF8GsI7"
      },
      "outputs": [],
      "source": [
        "# Importing All Necessary Libraries\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAuya8N2KPWz"
      },
      "outputs": [],
      "source": [
        "# Importing the Dataset\n",
        "\n",
        "# Define the paths to the train and test folders\n",
        "train_normal_path = '/content/drive/MyDrive/PneumoniaCTData/chest_xray/train/NORMAL'\n",
        "train_pneumonia_path = '/content/drive/MyDrive/PneumoniaCTData/chest_xray/train/PNEUMONIA'\n",
        "test_normal_path = '/content/drive/MyDrive/PneumoniaCTData/chest_xray/test/NORMAL'\n",
        "test_pneumonia_path = '/content/drive/MyDrive/PneumoniaCTData/chest_xray/test/PNEUMONIA'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPerowYwg9D-"
      },
      "outputs": [],
      "source": [
        "def preprocess_images(image_paths):\n",
        "    preprocessed_images = []\n",
        "    for path in image_paths:\n",
        "        # Load the image without resizing\n",
        "        image = cv2.imread(path)\n",
        "        preprocessed_images.append(image)\n",
        "    return np.array(preprocessed_images)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of image paths for training and testing\n",
        "train_normal_images = [os.path.join(train_normal_path, image) for image in os.listdir(train_normal_path)]\n",
        "train_pneumonia_images = [os.path.join(train_pneumonia_path, image) for image in os.listdir(train_pneumonia_path)]\n",
        "test_normal_images = [os.path.join(test_normal_path, image) for image in os.listdir(test_normal_path)]\n",
        "test_pneumonia_images = [os.path.join(test_pneumonia_path, image) for image in os.listdir(test_pneumonia_path)]\n",
        "\n",
        "# Preprocess the images\n",
        "train_normal_data = preprocess_images(train_normal_images)\n",
        "train_pneumonia_data = preprocess_images(train_pneumonia_images)\n",
        "test_normal_data = preprocess_images(test_normal_images)\n",
        "test_pneumonia_data = preprocess_images(test_pneumonia_images)"
      ],
      "metadata": {
        "id": "358fsgjyHVh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a7ac99-01be-4915-f1bf-f735874ae5f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-c66f91b383da>:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(preprocessed_images)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRotef1xz1U6"
      },
      "outputs": [],
      "source": [
        "# Create labels for the data\n",
        "train_normal_labels = np.zeros(len(train_normal_data))\n",
        "train_pneumonia_labels = np.ones(len(train_pneumonia_data))\n",
        "test_normal_labels = np.zeros(len(test_normal_data))\n",
        "test_pneumonia_labels = np.ones(len(test_pneumonia_data))\n",
        "\n",
        "# Concatenate the data and labels\n",
        "X_train = np.concatenate((train_normal_data, train_pneumonia_data), axis=0)\n",
        "y_train = np.concatenate((train_normal_labels, train_pneumonia_labels), axis=0)\n",
        "X_test = np.concatenate((test_normal_data, test_pneumonia_data), axis=0)\n",
        "y_test = np.concatenate((test_normal_labels, test_pneumonia_labels), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRV9V31PET2G"
      },
      "outputs": [],
      "source": [
        "# Resize data for deep learning\n",
        "X_train= np.array(X_train).reshape(-1, 200, 200, 1)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test).reshape(-1, 200, 200, 1)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c6NtWUkB6Yl"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation\n",
        "data_augmenter = ImageDataGenerator(\n",
        "        featurewise_center=False,\n",
        "        samplewise_center=False,\n",
        "        rotation_range=45,\n",
        "        zoom_range = 0.2,\n",
        "        featurewise_std_normalization=False,\n",
        "        samplewise_std_normalization=False,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True)\n",
        "\n",
        "data_augmenter.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1KJZ0eTkY0U"
      },
      "outputs": [],
      "source": [
        "# Reshape X_train and X_test to have 2 dimensions\n",
        "num_train_samples = X_train.shape[0]\n",
        "num_test_samples = X_test.shape[0]\n",
        "X_train = X_train.reshape(num_train_samples, -1)\n",
        "X_test = X_test.reshape(num_test_samples, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kr8yTfXlwyK"
      },
      "outputs": [],
      "source": [
        "# Standardize Data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnCu6fSTz3Wh",
        "outputId": "4a55bd74-6686-41b2-f93a-dce7e9dbb8a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNN Results:\n",
            "Accuracy: 0.7756410256410257\n",
            "F1 Score: 0.8461538461538463\n",
            "Confusion Matrix:\n",
            "[[ 99 135]\n",
            " [  5 385]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate K-Nearest Neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=4)\n",
        "knn.fit(X_train, y_train)\n",
        "knn_predictions = knn.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
        "knn_f1 = f1_score(y_test, knn_predictions)\n",
        "knn_confusion_matrix = confusion_matrix(y_test, knn_predictions)\n",
        "\n",
        "# Print the evaluation results for KNN\n",
        "print(\"KNN Results:\")\n",
        "print(\"Accuracy:\", knn_accuracy)\n",
        "print(\"F1 Score:\", knn_f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(knn_confusion_matrix)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EowvKoocz5Me",
        "outputId": "09fb4754-3f2b-41ba-9443-58ce8f6d4db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Results:\n",
            "Accuracy: 0.7419871794871795\n",
            "F1 Score: 0.8270676691729324\n",
            "Confusion Matrix:\n",
            "[[ 78 156]\n",
            " [  5 385]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "logreg_predictions = logreg.predict(X_test)\n",
        "logreg_accuracy = accuracy_score(y_test, logreg_predictions)\n",
        "logreg_f1 = f1_score(y_test, logreg_predictions)\n",
        "logreg_confusion_matrix = confusion_matrix(y_test, logreg_predictions)\n",
        "\n",
        "# Print the evaluation results for Logistic Regression\n",
        "print(\"Logistic Regression Results:\")\n",
        "print(\"Accuracy:\", logreg_accuracy)\n",
        "print(\"F1 Score:\", logreg_f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(logreg_confusion_matrix)\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqpUpHlJz-iY",
        "outputId": "e2d35496-7cd6-48cc-ad1c-3eacc152c7ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "163/163 [==============================] - 2557s 16s/step - loss: 3.2185 - accuracy: 0.8861\n",
            "Epoch 2/3\n",
            "163/163 [==============================] - 2548s 16s/step - loss: 0.0927 - accuracy: 0.9666\n",
            "Epoch 3/3\n",
            "163/163 [==============================] - 2563s 16s/step - loss: 0.0465 - accuracy: 0.9818\n",
            "20/20 [==============================] - 77s 4s/step\n",
            "CNN Results:\n",
            "Accuracy: 0.7227564102564102\n",
            "F1 Score: 0.8177028451001054\n",
            "Confusion Matrix:\n",
            "[[ 63 171]\n",
            " [  2 388]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Reshape X_train and X_test\n",
        "X_train = np.reshape(X_train, (-1, 200, 200, 1))\n",
        "X_test = np.reshape(X_test, (-1, 200, 200, 1))\n",
        "\n",
        "# Train and evaluate CNN\n",
        "\n",
        "# CNN model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', input_shape=X_train.shape[1:], padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=3, batch_size=32)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "cnn_predictions = model.predict(X_test)\n",
        "cnn_predictions = np.round(cnn_predictions).flatten()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "cnn_accuracy = accuracy_score(y_test, cnn_predictions)\n",
        "cnn_f1 = f1_score(y_test, cnn_predictions)\n",
        "cnn_confusion_matrix = confusion_matrix(y_test, cnn_predictions)\n",
        "\n",
        "# Print the evaluation results for CNN\n",
        "print(\"CNN Results:\")\n",
        "print(\"Accuracy:\", cnn_accuracy)\n",
        "print(\"F1 Score:\", cnn_f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cnn_confusion_matrix)\n",
        "print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}